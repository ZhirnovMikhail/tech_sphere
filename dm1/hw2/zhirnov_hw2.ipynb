{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Алгоритмы интеллектуальной обработки больших объемов данных\n",
    "## Домашнее задание №2 - Дерево решений\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Общая информация**\n",
    "\n",
    "**Срок сдачи:** до 1 ноября 2018, 06:00 \n",
    "**Штраф за опоздание:** -2 балла после 06:00 1 ноября, -4 балла после 06:00 8 ноября, -6 баллов после 06:00 15 ноября\n",
    "\n",
    "При отправлении ДЗ указывайте фамилию в названии файла   \n",
    "\n",
    "\n",
    "Присылать ДЗ необходимо в виде ссылки на свой github репозиторий в slack @alkhamush\n",
    "Необходимо в slack создать таск в приватный чат:   \n",
    "/todo Фамилия Имя *ссылка на гитхаб* @alkhamush   \n",
    "Пример:   \n",
    "/todo Ксения Стройкова https://github.com/stroykova/spheremailru/stroykova_hw2.ipynb @alkhamush   \n",
    "\n",
    "Используйте данный Ipython Notebook при оформлении домашнего задания."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Задание 1 (4 балла)\n",
    "Разберитесь в коде MyDecisionTreeClassifier, который уже частично реализован. В комментариях, где написано \"Что делает этот блок кода?\", ответьте на этот вопрос. Допишите код там, где написано \"Ваш код\". Ваша реализация дерева должна работать по точности не хуже DecisionTreeClassifier из sklearn. Точность проверяется на wine и Speed Dating Data.\n",
    "\n",
    "###### Задание 2 (2 балла)\n",
    "Добиться скорости работы fit такой, чтобы она была медленнее sklearn не более чем в 10 раз. Скорость проверяем на  wine и Speed Dating Data. Для ускорения используем только numpy.\n",
    "\n",
    "###### Задание 3 (2 балла)\n",
    "Добавьте функционал, который определяет значения feature importance. Выведите 10 главных фичей под пунктом Задание 3 (уже написано ниже) для MyDecisionTreeClassifier и DecisionTreeClassifier так, чтобы сразу были видны выводы и по MyDecisionTreeClassifier, и по DecisionTreeClassifier. Используем данные Speed Dating Data.\n",
    "\n",
    "###### Задание 4 (2 балла)\n",
    "С помощью GridSearchCV или RandomSearchCV подберите наиболее оптимальные параметры для случайного леса (Выберете 2-3 параметра). Используем данные Speed Dating Data. Задание реализуйте под пунктом Задание 5 (уже написано ниже)\n",
    "\n",
    "\n",
    "**Штрафные баллы:**\n",
    "\n",
    "1. Невыполнение PEP8 -1 балл\n",
    "2. Отсутствие фамилии в имени скрипта (скрипт должен называться по аналогии со stroykova_hw2.ipynb) -1 балл\n",
    "3. Все строчки должны быть выполнены. Нужно, чтобы output команды можно было увидеть уже в git'е. В противном случае -1 балл\n",
    "4. При оформлении ДЗ нужно пользоваться данным файлом в качестве шаблона. Не нужно удалять и видоизменять написанный код и текст. В противном случае -1 балл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The pycodestyle_magic extension is already loaded. To reload it, use:\n",
      "  %reload_ext pycodestyle_magic\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import KFold, train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext pycodestyle_magic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%pycodestyle\n",
    "\n",
    "\n",
    "class MyDecisionTreeClassifier:\n",
    "    NON_LEAF_TYPE = 0\n",
    "    LEAF_TYPE = 1\n",
    "\n",
    "    def __init__(self,\n",
    "                 min_samples_split=2,\n",
    "                 max_depth=None,\n",
    "                 sufficient_share=1.0,\n",
    "                 criterion='gini',\n",
    "                 max_features=None):\n",
    "\n",
    "        self.tree = dict()\n",
    "        # Дерево реализовано словарём, где ключём\n",
    "        # элемнта является уникальный идентефикатор узла дерева\n",
    "        # Значение является кортедж [тип узла, номер аргумета,\n",
    "        # порог для аргумента]\n",
    "        # тип узла NON_LEAF_TYPE или LEAF_TYPE\n",
    "\n",
    "        self.min_samples_split = min_samples_split\n",
    "        # Минимальное количество элементов выборки в узел, чтобы\n",
    "        # его можно было делить\n",
    "        # Иначе вершина\n",
    "\n",
    "        self.max_depth = max_depth\n",
    "        # Максимальная глубина дерева\n",
    "\n",
    "        self.sufficient_share = sufficient_share\n",
    "        # Минимальная необходимая доля класса в узле, чтобы определить его как\n",
    "        # Лист этого класса\n",
    "\n",
    "        self.num_class = -1\n",
    "        # Кол-во классов\n",
    "\n",
    "        self.feature_importances_ = None\n",
    "        # Выбор меры прироста информации\n",
    "\n",
    "        if criterion == 'gini':\n",
    "            self.G_function = self.__gini\n",
    "        elif criterion == 'entropy':\n",
    "            self.G_function = self.__entropy\n",
    "        elif criterion == 'misclass':\n",
    "            self.G_function = self.__misclass\n",
    "        else:\n",
    "            print('invalid criterion name')\n",
    "            raise\n",
    "\n",
    "        if max_features == 'sqrt':\n",
    "            self.get_feature_ids = self.__get_feature_ids_sqrt\n",
    "        elif max_features == 'log2':\n",
    "            self.get_feature_ids = self.__get_feature_ids_log2\n",
    "        elif max_features is None:\n",
    "            self.get_feature_ids = self.__get_feature_ids_N\n",
    "        else:\n",
    "            print('invalid max_features name')\n",
    "            raise\n",
    "        # Кол-во критериев для анализа\n",
    "\n",
    "    def __gini(self, l_c, l_s, r_c, r_s):\n",
    "        l_s = l_s.astype('float')\n",
    "        r_s = r_s.astype('float')\n",
    "\n",
    "        return (((1 - (((l_c / l_s) ** 2).sum(axis=1))).\n",
    "                reshape(-1, 1) * l_s / (l_s + r_s) +\n",
    "                (1 - (((r_c / r_s) ** 2).sum(axis=1))).\n",
    "                reshape(-1, 1) * r_s / (l_s + r_s)))\n",
    "\n",
    "    def __entropy(self, l_c, l_s, r_c, r_s):\n",
    "\n",
    "        l_c = np.nan_to_num(l_c)\n",
    "        r_c = np.nan_to_num(r_c)\n",
    "\n",
    "        l_c /= l_s\n",
    "        r_c /= r_s\n",
    "\n",
    "        return (-(l_c * l_c.log2()).sum(axis=1).\n",
    "                reshape(-1, 1) * l_s / (l_s + r_s) -\n",
    "                (r_c * r_c.log2()).sum(axis=1).\n",
    "                reshape(-1, 1) * r_s / (l_s + r_s))\n",
    "\n",
    "    def __misclass(self, l_c, l_s, r_c, r_s):\n",
    "\n",
    "        l_c = np.nan_to_num(l_c)\n",
    "        r_c = np.nan_to_num(r_c)\n",
    "\n",
    "        l_c /= l_s\n",
    "        r_c /= r_s\n",
    "\n",
    "        return (1 - l_c.max(axis=1)).reshape(-1, 1) * l_s / (l_s + r_s) + \\\n",
    "            (1 - r_c.max(axis=1)).reshape(-1, 1) * r_s / (l_s + r_s)\n",
    "\n",
    "    def __get_feature_ids_sqrt(self, n_feature):\n",
    "        feature_ids = range(n_feature)\n",
    "        np.random.shuffle(feature_ids)\n",
    "\n",
    "        return features_ids[:int(math.sqrt(feature_ids.size))]\n",
    "        # Выбираем sqrt(N) случайных критериев для анализа\n",
    "\n",
    "    def __get_feature_ids_log2(self, n_feature):\n",
    "        feature_ids = range(n_feature)\n",
    "        np.random.shuffle(feature_ids)\n",
    "\n",
    "        return features_ids[:int(math.log(feature_ids.size, 2))]\n",
    "        # Выбираем log2(N) случайных критериев для анализа\n",
    "\n",
    "    def __get_feature_ids_N(self, n_feature):\n",
    "        return np.arange(n_feature)\n",
    "        # Выбираем все критерии для анализа\n",
    "\n",
    "    def __sort_samples(self, x, y):\n",
    "        '''\n",
    "        Сортирует х и у в порядке возрастания х\n",
    "        '''\n",
    "\n",
    "        sorted_idx = x.argsort()\n",
    "\n",
    "        return x[sorted_idx], y[sorted_idx]\n",
    "\n",
    "    def __div_samples(self, x, y, feature_id, threshold):\n",
    "        '''\n",
    "        Делит выборку на две части: левую, значение ключевого атрибута\n",
    "        которой больше порога и правую состоящую из остальных\n",
    "        '''\n",
    "\n",
    "        left_mask = x[:, feature_id] >= threshold\n",
    "        right_mask = ~left_mask\n",
    "\n",
    "        return x[left_mask], x[right_mask], y[left_mask], y[right_mask]\n",
    "\n",
    "    def __find_threshold(self, x, y):\n",
    "        '''\n",
    "        Поиск порога критерия для разделения выборки на две части\n",
    "        '''\n",
    "\n",
    "        sorted_x, sorted_y = self.__sort_samples(x, y)\n",
    "        # Сортировка выбранного атрибута и целевого\n",
    "        # значнения по возрастанию значения атрибута\n",
    "\n",
    "        class_number = np.unique(y).shape[0]\n",
    "        # Кол-во классов в выборке\n",
    "\n",
    "        samples_clip = int(self.min_samples_split / 2)\n",
    "\n",
    "        splitted_sorted_y = sorted_y[samples_clip:-samples_clip]\n",
    "        # Выделение крайних значений в сортированой выборке\n",
    "\n",
    "        r_border_ids = np.where(splitted_sorted_y[:-1] !=\n",
    "                                splitted_sorted_y[1:])[0] + (samples_clip + 1)\n",
    "\n",
    "        # Выделение позиций значений целовой\n",
    "        # функции, в которых произошло изменение класса\n",
    "        # Позиция правого числа в необрезанной сориторованной выборке\n",
    "        # Отсечённые части не учитываются\n",
    "\n",
    "        if len(r_border_ids) == 0:\n",
    "            return np.inf, None\n",
    "\n",
    "        # Если выборка такая, что в обрезанной части\n",
    "        # Только одинаковые элементы, то вернуть значение неопределенности\n",
    "        # В разделённой выборке, следовательно критерий не будет выбран\n",
    "\n",
    "        eq_el_count = r_border_ids - \\\n",
    "            np.append([samples_clip], r_border_ids[:-1])\n",
    "        one_hot_code = np.zeros((r_border_ids.shape[0], class_number))\n",
    "        one_hot_code[np.arange(r_border_ids.shape[0]),\n",
    "                     sorted_y[r_border_ids - 1]] = 1\n",
    "\n",
    "        class_increments = one_hot_code * eq_el_count.reshape(-1, 1)\n",
    "        class_increments[0] += np.bincount(sorted_y[:samples_clip],\n",
    "                                           minlength=class_number)\n",
    "        # Создаём таблицу кол-во столбцов - кол-во классов\n",
    "        # Кол-во строк - кол-во последовательных \"кусков\"\n",
    "        # в сотрировнной и обрезаной выборке цел. ф-ии\n",
    "        # Кусок i состоит из одинаковых значений класса\n",
    "        # В [i, j] кол-во элеметов класса j в куске i\n",
    "        # Учитываются все первые эл-ты, в том числе и до границы обрезания\n",
    "        # Последние (за границей) не учитываются\n",
    "\n",
    "        l_class_count = np.cumsum(class_increments, axis=0, dtype=np.float32)\n",
    "        r_class_count = (np.bincount(sorted_y) -\n",
    "                         l_class_count).astype(np.float32)\n",
    "        l_sizes = r_border_ids.reshape(l_class_count.shape[0], 1)\n",
    "        r_sizes = sorted_y.shape[0] - l_sizes\n",
    "\n",
    "        # В [i,j] l_class_count кол-во элементов j\n",
    "        # го класса в отсортированной выборке\n",
    "        # до i-го куска включая, в r_class_count - после\n",
    "        # l_size - координата куска слева (коорд. правого\n",
    "        # числа в отсортировннаой выборке),\n",
    "        # r_size - координата куска справа (коорд. лев.\n",
    "        # числа в отсортировннаой выборке)\n",
    "\n",
    "        gs = self.G_function(l_class_count, l_sizes, r_class_count, r_sizes)\n",
    "        idx = np.argmin(gs)\n",
    "\n",
    "        # Считаем меру неопределённости для каждого\n",
    "        # разбиения и выбираем минимум\n",
    "\n",
    "        left_el_id = l_sizes[idx][0]\n",
    "        return gs[idx], (sorted_x[left_el_id-1] +\n",
    "                         sorted_x[left_el_id]) / 2.0\n",
    "        # Возвращаем значние неопределённости и порог в сортированном массиве\n",
    "\n",
    "    def __fit_node(self, X, y, node_id, depth, pred_f=-1):\n",
    "        ration = np.bincount(y, minlength=3).astype(np.float32)\n",
    "        ration = ration / ration.sum()\n",
    "        # Считаем соотношение частей классов в текущей выборке\n",
    "\n",
    "        if not (self.max_depth is None) and (depth >= self.max_depth) or \\\n",
    "                X.shape[0] <= self.min_samples_split or \\\n",
    "                ration.max() >= self.sufficient_share:\n",
    "\n",
    "            res = np.argmax(np.bincount(y))\n",
    "            self.tree.update(\n",
    "                {node_id: [self.__class__.LEAF_TYPE, res, ration]})\n",
    "            return\n",
    "\n",
    "        # Условие узла как листа: глубина больше макс. допустимой глубины или\n",
    "        # кол-во элементов выборки в узле равно или менее минимального чила\n",
    "        # Если максимальная доля какого\n",
    "        # -либо класса больше установленного порога\n",
    "        # Объявить узел листом\n",
    "\n",
    "        y_tmp = np.array(y)\n",
    "        for i in range(np.unique(y).size):\n",
    "            y[y == np.unique(y)[i]] = i\n",
    "        # Изменяем значения целевой переменной\n",
    "        # на числа от 0 до кол-ва уникальных значений\n",
    "\n",
    "        features_ids = self.get_feature_ids(X.shape[1])\n",
    "        # Выбор характеристик для анализа\n",
    "\n",
    "        imp_arr = np.zeros(features_ids.size, dtype=np.float32)\n",
    "        threshold_arr = np.zeros(features_ids.size, dtype=np.float32)\n",
    "        # Массив мин. неопределенности и массив порогов для хар-ки\n",
    "\n",
    "        for i in range(features_ids.size):\n",
    "            imp_arr[i], threshold_arr[i] = self.__find_threshold(\n",
    "                X.T[features_ids[i]], y)\n",
    "        # Поиск мин. неопр. и соответсвующего порога для каждого критерия\n",
    "\n",
    "        y = y_tmp\n",
    "        # Восстанавливаем значения целевой переменной\n",
    "\n",
    "        if np.isinf(imp_arr).all():\n",
    "            res = np.argmax(np.bincount(y))\n",
    "            self.tree.update(\n",
    "                {node_id: [self.__class__.LEAF_TYPE, res, ration]})\n",
    "            return None\n",
    "        # Если все значения в разбиение бб\n",
    "        # возвращаем значение большей части класса\n",
    "\n",
    "        min_imp_feature = np.argmin(imp_arr)\n",
    "        # Выбор свойства с наименьшим значение неопределнности\n",
    "\n",
    "        if np.argwhere(imp_arr == imp_arr.min())[:, 0].size != 1:\n",
    "            k = np.argwhere(imp_arr == imp_arr.min())[:, 0]\n",
    "            np.random.shuffle(k)\n",
    "            min_imp_feature = k[0]\n",
    "        # Если таких значений несколько, то выбираем случайное\n",
    "\n",
    "        threshold = threshold_arr[min_imp_feature]\n",
    "        # Выделение соответсвующего порога\n",
    "\n",
    "        feature_pos = features_ids[min_imp_feature]\n",
    "        self.feature_importances_[feature_pos] += 1\n",
    "        x_l, x_r, y_l, y_r = self.__div_samples(X, y, feature_pos, threshold)\n",
    "        # Разделение выборки на две части для левого и правого листа\n",
    "\n",
    "        if x_r.shape[0] == 0 or x_l.shape[0] == 0:\n",
    "            res = np.argmax(np.bincount(y))\n",
    "            self.tree.update(\n",
    "                {node_id: [self.__class__.LEAF_TYPE, res, ration]})\n",
    "            return None\n",
    "            # Если одна часть пустая, то лист\n",
    "\n",
    "        self.tree.update(\n",
    "            {node_id: [self.__class__.NON_LEAF_TYPE, feature_pos, threshold]})\n",
    "        # Добавление текущего листа в дерево\n",
    "\n",
    "        self.__fit_node(x_l, y_l, node_id * 2 + 1, depth + 1)\n",
    "        self.__fit_node(x_r, y_r, node_id * 2 + 2, depth + 1)\n",
    "        # Создаём две подвершины\n",
    "\n",
    "        return None\n",
    "\n",
    "    def fit(self, x, y):\n",
    "        self.num_class = np.unique(y).size\n",
    "        self.feature_importances_ = np.zeros(x.shape[1])\n",
    "        self.__fit_node(x, y, 0, 0)\n",
    "\n",
    "    def __predict_class(self, x, node_id):\n",
    "        node = self.tree[node_id]\n",
    "        if node[0] == self.__class__.NON_LEAF_TYPE:\n",
    "            _, feature_id, threshold = node\n",
    "            if x[feature_id] > threshold:\n",
    "                return self.__predict_class(x, 2 * node_id + 1)\n",
    "            else:\n",
    "                return self.__predict_class(x, 2 * node_id + 2)\n",
    "        else:\n",
    "            return node[1]\n",
    "\n",
    "    def __predict_probs(self, x, node_id):\n",
    "        node = self.tree[node_id]\n",
    "        if node[0] == self.__class__.NON_LEAF_TYPE:\n",
    "            _, feature_id, threshold = node\n",
    "            if x[feature_id] > threshold:\n",
    "                return self.__predict_probs(x, 2 * node_id + 1)\n",
    "            else:\n",
    "                return self.__predict_probs(x, 2 * node_id + 2)\n",
    "        else:\n",
    "            return node[2]\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.array([self.__predict_class(x, 0) for x in X])\n",
    "\n",
    "    def predict_probs(self, X):\n",
    "        return np.array([self.__predict_probs(x, 0) for x in X])\n",
    "\n",
    "    def fit_predict(self, x_train, y_train, predicted_x):\n",
    "        self.fit(x_train, y_train)\n",
    "        return self.predict(predicted_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%pycodestyle\n",
    "\n",
    "my_clf = MyDecisionTreeClassifier(min_samples_split=2)\n",
    "clf = DecisionTreeClassifier(min_samples_split=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%pycodestyle\n",
    "\n",
    "wine = load_wine()\n",
    "X_train, X_test, y_train, y_test = train_test_split(wine.data,\n",
    "                                                    wine.target,\n",
    "                                                    test_size=0.1,\n",
    "                                                    stratify=wine.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка скорости работы на wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.25 ms, sys: 277 µs, total: 2.53 ms\n",
      "Wall time: 8.7 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 29.9 ms, sys: 3.74 ms, total: 33.6 ms\n",
      "Wall time: 41.1 ms\n"
     ]
    }
   ],
   "source": [
    "%time my_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка качества работы на wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9407407407407408"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_pred=clf.predict(X_test), y_true=y_test, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9440559440559441"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_pred=my_clf.predict(X_test), y_true=y_test, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка данных Speed Dating Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%pycodestyle\n",
    "\n",
    "df = pd.read_csv('Speed Dating Data.csv',\n",
    "                 encoding='cp1251')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%pycodestyle\n",
    "\n",
    "df = df.iloc[:, :97]\n",
    "# Оставляем первые 97 элементов\n",
    "\n",
    "df = df.drop(['condtn', 'round', 'position', 'positin1', 'order',\n",
    "              'partner', 'id', 'idg', 'age_o', 'race_o', 'pf_o_att',\n",
    "              'pf_o_sin', 'pf_o_int', 'pf_o_fun', 'pf_o_amb',\n",
    "              'pf_o_sha', 'dec_o', 'attr_o', 'sinc_o', 'intel_o',\n",
    "              'fun_o', 'amb_o', 'shar_o', 'like_o', 'prob_o', 'met_o',\n",
    "              'field', 'from', 'zipcode', 'career', 'sports', 'tvsports',\n",
    "              'exercise', 'dining', 'museums', 'art', 'hiking', 'gaming',\n",
    "              'clubbing', 'reading', 'tv', 'theater', 'movies', 'concerts',\n",
    "              'music', 'shopping', 'yoga', 'expnum', 'undergra', 'field'\n",
    "              ], axis=1)\n",
    "# Удаляем ненужные столбцы параметров\n",
    "\n",
    "df.loc[:, 'field_cd'] = df.loc[:, 'field_cd'].fillna(0)\n",
    "# Заполняем NaN нулями\n",
    "\n",
    "tmp = pd.get_dummies(df.loc[:, 'field_cd'], prefix='field_cd', prefix_sep='=')\n",
    "df = pd.concat([df, tmp], axis=1)\n",
    "# Кодируем категориальные признаки и конкатенируем таблицы\n",
    "\n",
    "df = df.dropna(subset=['imprelig', 'imprace', 'age', 'date'])\n",
    "# Удаляем семплы, где пропущены значения в каком-либо из столбцов выше\n",
    "\n",
    "df.loc[:, 'mn_sat'] = df.loc[:, 'mn_sat'].str.replace(',', '').astype(np.float)\n",
    "df.loc[:, 'mn_sat'] = df.mn_sat.fillna(-999)\n",
    "# Заполняем NaN малыми числами\n",
    "\n",
    "df.loc[:, 'tuition'] = df.loc[:,\n",
    "                              'tuition'].str.replace(',', '').astype(np.float)\n",
    "df.loc[:, 'tuition'] = df.tuition.fillna(-999)\n",
    "# Заполняем NaN малыми числами\n",
    "\n",
    "df.loc[:, 'income'] = df.loc[:, 'income'].str.replace(',', '').astype(np.float)\n",
    "df.loc[:, 'income'] = df.loc[:, 'income'].fillna(-999)\n",
    "# Заполняем NaN малыми числами\n",
    "\n",
    "df.loc[:, 'career_c'] = df.loc[:, 'career_c'].fillna(0)\n",
    "# Заполняем NaN нулями\n",
    "\n",
    "df.loc[:, 'temp_totalsum'] = df.loc[:, ['attr1_1', 'sinc1_1', 'intel1_1',\n",
    "                                        'fun1_1', 'amb1_1',\n",
    "                                        'shar1_1']].sum(axis=1)\n",
    "df.loc[:, ['attr1_1', 'sinc1_1', 'intel1_1',\n",
    "           'fun1_1', 'amb1_1',\n",
    "           'shar1_1']] = \\\n",
    "           (df.loc[:, ['attr1_1', 'sinc1_1', 'intel1_1',\n",
    "                       'fun1_1', 'amb1_1',\n",
    "                       'shar1_1']].T / df.loc[:, 'temp_totalsum'].T).T * 100\n",
    "\n",
    "df.loc[:, 'temp_totalsum'] = df.loc[:, ['attr2_1', 'sinc2_1', 'intel2_1',\n",
    "                                        'fun2_1', 'amb2_1',\n",
    "                                        'shar2_1']].sum(axis=1)\n",
    "df.loc[:, ['attr2_1', 'sinc2_1', 'intel2_1',\n",
    "           'fun2_1', 'amb2_1', 'shar2_1']] = \\\n",
    "           (df.loc[:, ['attr2_1', 'sinc2_1', 'intel2_1',\n",
    "                       'fun2_1', 'amb2_1', 'shar2_1']].T /\n",
    "            df.loc[:, 'temp_totalsum'].T).T * 100\n",
    "\n",
    "df = df.drop(['temp_totalsum'], axis=1)\n",
    "# Удаляем временную колонку\n",
    "\n",
    "for i in [4, 5]:\n",
    "    feat = ['attr{}_1'.format(i), 'sinc{}_1'.format(i),\n",
    "            'intel{}_1'.format(i), 'fun{}_1'.format(i),\n",
    "            'amb{}_1'.format(i), 'shar{}_1'.format(i)]\n",
    "    if i != 4:\n",
    "        feat.remove('shar{}_1'.format(i))\n",
    "    df = df.drop(feat, axis=1)\n",
    "# Признаки attr4 и attr5 выбросим\n",
    "\n",
    "df = df.drop(['wave'], axis=1)\n",
    "# Удаляем временную колонку\n",
    "\n",
    "df_male = df.query('gender == 1').drop_duplicates(subset=['iid', 'pid'])\\\n",
    "                                 .drop(['gender'], axis=1)\\\n",
    "                                 .dropna()\n",
    "# Теперь создадим таблицу с мужчинами\n",
    "df_female = df.query('gender == 0').drop_duplicates(subset=['iid'])\\\n",
    "                                   .drop(['gender', 'match', 'int_corr',\n",
    "                                          'samerace'], axis=1).dropna()\n",
    "# Таблицу с женщинами\n",
    "\n",
    "df_female.columns = df_female.columns + '_f'\n",
    "# Создадим постфикс для названий колонок\n",
    "\n",
    "df_female = df_female.drop(['pid_f'], axis=1)\n",
    "# Удаляем ненужную колонку\n",
    "\n",
    "df_pair = df_male.join(df_female.set_index('iid_f'), on='pid', how='inner')\n",
    "# Связываем таблицы\n",
    "\n",
    "df_pair = df_pair.drop(['iid', 'pid'], axis=1)\n",
    "# Удаляем ненужную колонку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%pycodestyle\n",
    "\n",
    "X = df_pair.iloc[:, 1:].values\n",
    "y = df_pair.iloc[:, 0].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1,\n",
    "                                                    random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка скорости работы на Speed Dating Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 191 ms, sys: 120 µs, total: 191 ms\n",
      "Wall time: 205 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.46 s, sys: 3.15 ms, total: 3.46 s\n",
      "Wall time: 3.59 s\n"
     ]
    }
   ],
   "source": [
    "%time my_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка качества работы на Speed Dating Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5657593180812995"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%%pycodestyle\n",
    "\n",
    "clf = DecisionTreeClassifier(min_samples_split=2)\n",
    "clf.fit(X_train, y_train)\n",
    "f1_score(y_pred=clf.predict(X_test),\n",
    "         y_true=y_test.reshape(-1, 1),\n",
    "         average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47548704774138295"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%%pycodestyle\n",
    "\n",
    "my_clf = MyDecisionTreeClassifier(min_samples_split=2)\n",
    "my_clf.fit(X_train, y_train)\n",
    "f1_score(y_pred=my_clf.predict(X_test), y_true=y_test, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%pycodestyle\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1,\n",
    "                                                    random_state=123)\n",
    "\n",
    "my_clf = DecisionTreeClassifier(min_samples_split=2)\n",
    "my_clf.fit(X_train, y_train)\n",
    "\n",
    "clf = MyDecisionTreeClassifier(min_samples_split=2)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0 72 74 68 70 67 58 17 66]\n",
      "[ 0 55 20 75 85 56 72 78 11]\n"
     ]
    }
   ],
   "source": [
    "#%%pycodestyle\n",
    "\n",
    "print(np.argsort(my_clf.feature_importances_)[:-10:-1])\n",
    "print(np.argsort(clf.feature_importances_)[:-10:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%pycodestyle\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1,\n",
    "                                                    random_state=123)\n",
    "\n",
    "my_clf = DecisionTreeClassifier(min_samples_split=2)\n",
    "my_clf.fit(X_train, y_train)\n",
    "\n",
    "clf = MyDecisionTreeClassifier(min_samples_split=2)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8225"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%%pycodestyle\n",
    "\n",
    "parameters = {'n_estimators': np.arange(4, 20),\n",
    "              'min_samples_split': np.arange(2, 10)}\n",
    "\n",
    "clf = GridSearchCV(RandomForestClassifier(), parameters)\n",
    "clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
